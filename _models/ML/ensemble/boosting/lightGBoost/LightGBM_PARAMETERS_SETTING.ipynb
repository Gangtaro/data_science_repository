{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, ParameterGrid\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, f1_score\n",
    "from sklearn.datasets import load_iris, load_digits, load_boston\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rng = np.random.RandomState(950530)\n",
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.613545\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 0.508422\n",
      "[3]\tvalid_0's l2: 0.424955\n",
      "[4]\tvalid_0's l2: 0.352433\n",
      "[5]\tvalid_0's l2: 0.299748\n",
      "[6]\tvalid_0's l2: 0.253002\n",
      "[7]\tvalid_0's l2: 0.220251\n",
      "[8]\tvalid_0's l2: 0.190313\n",
      "[9]\tvalid_0's l2: 0.166706\n",
      "[10]\tvalid_0's l2: 0.144424\n",
      "[11]\tvalid_0's l2: 0.129655\n",
      "[12]\tvalid_0's l2: 0.115111\n",
      "[13]\tvalid_0's l2: 0.105544\n",
      "[14]\tvalid_0's l2: 0.0980449\n",
      "[15]\tvalid_0's l2: 0.0914526\n",
      "[16]\tvalid_0's l2: 0.0864362\n",
      "[17]\tvalid_0's l2: 0.0829129\n",
      "[18]\tvalid_0's l2: 0.0805249\n",
      "[19]\tvalid_0's l2: 0.0783062\n",
      "[20]\tvalid_0's l2: 0.0764294\n",
      "[21]\tvalid_0's l2: 0.07496\n",
      "[22]\tvalid_0's l2: 0.0738617\n",
      "[23]\tvalid_0's l2: 0.073135\n",
      "[24]\tvalid_0's l2: 0.072555\n",
      "[25]\tvalid_0's l2: 0.0721883\n",
      "[26]\tvalid_0's l2: 0.0719173\n",
      "[27]\tvalid_0's l2: 0.0724773\n",
      "[28]\tvalid_0's l2: 0.0730644\n",
      "[29]\tvalid_0's l2: 0.072905\n",
      "[30]\tvalid_0's l2: 0.0728819\n",
      "[31]\tvalid_0's l2: 0.0735359\n",
      "[32]\tvalid_0's l2: 0.0735193\n",
      "[33]\tvalid_0's l2: 0.0735403\n",
      "[34]\tvalid_0's l2: 0.0738162\n",
      "[35]\tvalid_0's l2: 0.0738706\n",
      "[36]\tvalid_0's l2: 0.0739413\n",
      "[37]\tvalid_0's l2: 0.0742227\n",
      "[38]\tvalid_0's l2: 0.0743018\n",
      "[39]\tvalid_0's l2: 0.0744234\n",
      "[40]\tvalid_0's l2: 0.0750513\n",
      "[41]\tvalid_0's l2: 0.0751431\n",
      "[42]\tvalid_0's l2: 0.0753396\n",
      "[43]\tvalid_0's l2: 0.0753842\n",
      "[44]\tvalid_0's l2: 0.0754965\n",
      "[45]\tvalid_0's l2: 0.0756008\n",
      "[46]\tvalid_0's l2: 0.0757002\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's l2: 0.0719173\n",
      "0.07191729349131536\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "lgb_model = lgb.LGBMRegressor(early_stopping_round = 20, metric = 'mse')\n",
    "lgb_model.fit(X_train, y_train,\n",
    "             eval_set = [(X_valid, y_valid)]) # NEEDS\n",
    "\n",
    "predictions = lgb_model.predict(X_valid)\n",
    "actuals = y_valid\n",
    "\n",
    "print(mean_squared_error(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "X = iris['data']\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.987072\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.89091\n",
      "[3]\tvalid_0's multi_logloss: 0.782331\n",
      "[4]\tvalid_0's multi_logloss: 0.688993\n",
      "[5]\tvalid_0's multi_logloss: 0.611978\n",
      "[6]\tvalid_0's multi_logloss: 0.551269\n",
      "[7]\tvalid_0's multi_logloss: 0.493302\n",
      "[8]\tvalid_0's multi_logloss: 0.450718\n",
      "[9]\tvalid_0's multi_logloss: 0.404287\n",
      "[10]\tvalid_0's multi_logloss: 0.371764\n",
      "[11]\tvalid_0's multi_logloss: 0.336915\n",
      "[12]\tvalid_0's multi_logloss: 0.309117\n",
      "[13]\tvalid_0's multi_logloss: 0.290616\n",
      "[14]\tvalid_0's multi_logloss: 0.265338\n",
      "[15]\tvalid_0's multi_logloss: 0.247972\n",
      "[16]\tvalid_0's multi_logloss: 0.230982\n",
      "[17]\tvalid_0's multi_logloss: 0.21855\n",
      "[18]\tvalid_0's multi_logloss: 0.207123\n",
      "[19]\tvalid_0's multi_logloss: 0.197597\n",
      "[20]\tvalid_0's multi_logloss: 0.189474\n",
      "[21]\tvalid_0's multi_logloss: 0.181595\n",
      "[22]\tvalid_0's multi_logloss: 0.176537\n",
      "[23]\tvalid_0's multi_logloss: 0.167184\n",
      "[24]\tvalid_0's multi_logloss: 0.164225\n",
      "[25]\tvalid_0's multi_logloss: 0.159228\n",
      "[26]\tvalid_0's multi_logloss: 0.157514\n",
      "[27]\tvalid_0's multi_logloss: 0.151442\n",
      "[28]\tvalid_0's multi_logloss: 0.149265\n",
      "[29]\tvalid_0's multi_logloss: 0.147155\n",
      "[30]\tvalid_0's multi_logloss: 0.145023\n",
      "[31]\tvalid_0's multi_logloss: 0.147633\n",
      "[32]\tvalid_0's multi_logloss: 0.146122\n",
      "[33]\tvalid_0's multi_logloss: 0.143017\n",
      "[34]\tvalid_0's multi_logloss: 0.143886\n",
      "[35]\tvalid_0's multi_logloss: 0.143466\n",
      "[36]\tvalid_0's multi_logloss: 0.140823\n",
      "[37]\tvalid_0's multi_logloss: 0.141755\n",
      "[38]\tvalid_0's multi_logloss: 0.145241\n",
      "[39]\tvalid_0's multi_logloss: 0.142531\n",
      "[40]\tvalid_0's multi_logloss: 0.144512\n",
      "[41]\tvalid_0's multi_logloss: 0.145932\n",
      "[42]\tvalid_0's multi_logloss: 0.143316\n",
      "[43]\tvalid_0's multi_logloss: 0.146284\n",
      "[44]\tvalid_0's multi_logloss: 0.147607\n",
      "[45]\tvalid_0's multi_logloss: 0.147994\n",
      "[46]\tvalid_0's multi_logloss: 0.153093\n",
      "[47]\tvalid_0's multi_logloss: 0.151823\n",
      "[48]\tvalid_0's multi_logloss: 0.150137\n",
      "[49]\tvalid_0's multi_logloss: 0.150962\n",
      "[50]\tvalid_0's multi_logloss: 0.151893\n",
      "[51]\tvalid_0's multi_logloss: 0.152913\n",
      "[52]\tvalid_0's multi_logloss: 0.15549\n",
      "[53]\tvalid_0's multi_logloss: 0.157241\n",
      "[54]\tvalid_0's multi_logloss: 0.15827\n",
      "[55]\tvalid_0's multi_logloss: 0.160917\n",
      "[56]\tvalid_0's multi_logloss: 0.162731\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's multi_logloss: 0.140823\n",
      "[[25  0  0]\n",
      " [ 0 24  5]\n",
      " [ 0  0 21]]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "lgb_model = lgb.LGBMClassifier(early_stopping_round = 20, metric = 'multi_logloss')\n",
    "lgb_model.fit(X_train, y_train,\n",
    "             eval_set = [(X_valid, y_valid)]) # NEEDS\n",
    "\n",
    "print(confusion_matrix(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.95551\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.816281\n",
      "[3]\tvalid_0's multi_logloss: 0.708683\n",
      "[4]\tvalid_0's multi_logloss: 0.620288\n",
      "[5]\tvalid_0's multi_logloss: 0.546995\n",
      "[6]\tvalid_0's multi_logloss: 0.483309\n",
      "[7]\tvalid_0's multi_logloss: 0.432137\n",
      "[8]\tvalid_0's multi_logloss: 0.385391\n",
      "[9]\tvalid_0's multi_logloss: 0.348436\n",
      "[10]\tvalid_0's multi_logloss: 0.320539\n",
      "[11]\tvalid_0's multi_logloss: 0.294368\n",
      "[12]\tvalid_0's multi_logloss: 0.268866\n",
      "[13]\tvalid_0's multi_logloss: 0.247843\n",
      "[14]\tvalid_0's multi_logloss: 0.229687\n",
      "[15]\tvalid_0's multi_logloss: 0.21402\n",
      "[16]\tvalid_0's multi_logloss: 0.20124\n",
      "[17]\tvalid_0's multi_logloss: 0.186713\n",
      "[18]\tvalid_0's multi_logloss: 0.176332\n",
      "[19]\tvalid_0's multi_logloss: 0.166914\n",
      "[20]\tvalid_0's multi_logloss: 0.159202\n",
      "[21]\tvalid_0's multi_logloss: 0.153756\n",
      "[22]\tvalid_0's multi_logloss: 0.146985\n",
      "[23]\tvalid_0's multi_logloss: 0.142102\n",
      "[24]\tvalid_0's multi_logloss: 0.137605\n",
      "[25]\tvalid_0's multi_logloss: 0.134159\n",
      "[26]\tvalid_0's multi_logloss: 0.131993\n",
      "[27]\tvalid_0's multi_logloss: 0.129672\n",
      "[28]\tvalid_0's multi_logloss: 0.127285\n",
      "[29]\tvalid_0's multi_logloss: 0.126657\n",
      "[30]\tvalid_0's multi_logloss: 0.12476\n",
      "[31]\tvalid_0's multi_logloss: 0.124205\n",
      "[32]\tvalid_0's multi_logloss: 0.122879\n",
      "[33]\tvalid_0's multi_logloss: 0.122632\n",
      "[34]\tvalid_0's multi_logloss: 0.123365\n",
      "[35]\tvalid_0's multi_logloss: 0.123504\n",
      "[36]\tvalid_0's multi_logloss: 0.12238\n",
      "[37]\tvalid_0's multi_logloss: 0.120717\n",
      "[38]\tvalid_0's multi_logloss: 0.119646\n",
      "[39]\tvalid_0's multi_logloss: 0.118839\n",
      "[40]\tvalid_0's multi_logloss: 0.118326\n",
      "[41]\tvalid_0's multi_logloss: 0.117972\n",
      "[42]\tvalid_0's multi_logloss: 0.117551\n",
      "[43]\tvalid_0's multi_logloss: 0.117575\n",
      "[44]\tvalid_0's multi_logloss: 0.116775\n",
      "[45]\tvalid_0's multi_logloss: 0.115575\n",
      "[46]\tvalid_0's multi_logloss: 0.114493\n",
      "[47]\tvalid_0's multi_logloss: 0.113895\n",
      "[48]\tvalid_0's multi_logloss: 0.112918\n",
      "[49]\tvalid_0's multi_logloss: 0.112017\n",
      "[50]\tvalid_0's multi_logloss: 0.110679\n",
      "[51]\tvalid_0's multi_logloss: 0.109447\n",
      "[52]\tvalid_0's multi_logloss: 0.110191\n",
      "[53]\tvalid_0's multi_logloss: 0.109383\n",
      "[54]\tvalid_0's multi_logloss: 0.1099\n",
      "[55]\tvalid_0's multi_logloss: 0.108386\n",
      "[56]\tvalid_0's multi_logloss: 0.108017\n",
      "[57]\tvalid_0's multi_logloss: 0.108731\n",
      "[58]\tvalid_0's multi_logloss: 0.108124\n",
      "[59]\tvalid_0's multi_logloss: 0.10875\n",
      "[60]\tvalid_0's multi_logloss: 0.109129\n",
      "[61]\tvalid_0's multi_logloss: 0.108193\n",
      "[62]\tvalid_0's multi_logloss: 0.108072\n",
      "[63]\tvalid_0's multi_logloss: 0.108744\n",
      "[64]\tvalid_0's multi_logloss: 0.108641\n",
      "[65]\tvalid_0's multi_logloss: 0.108814\n",
      "[66]\tvalid_0's multi_logloss: 0.108956\n",
      "[67]\tvalid_0's multi_logloss: 0.108912\n",
      "[68]\tvalid_0's multi_logloss: 0.109643\n",
      "[69]\tvalid_0's multi_logloss: 0.109604\n",
      "[70]\tvalid_0's multi_logloss: 0.110665\n",
      "[71]\tvalid_0's multi_logloss: 0.110508\n",
      "[72]\tvalid_0's multi_logloss: 0.11126\n",
      "[73]\tvalid_0's multi_logloss: 0.111105\n",
      "[74]\tvalid_0's multi_logloss: 0.111882\n",
      "[75]\tvalid_0's multi_logloss: 0.112297\n",
      "[76]\tvalid_0's multi_logloss: 0.111475\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_logloss: 0.108017\n",
      "\n",
      "[1]\tvalid_0's multi_logloss: 0.951932\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.819339\n",
      "[3]\tvalid_0's multi_logloss: 0.714381\n",
      "[4]\tvalid_0's multi_logloss: 0.62516\n",
      "[5]\tvalid_0's multi_logloss: 0.557524\n",
      "[6]\tvalid_0's multi_logloss: 0.500951\n",
      "[7]\tvalid_0's multi_logloss: 0.457237\n",
      "[8]\tvalid_0's multi_logloss: 0.416388\n",
      "[9]\tvalid_0's multi_logloss: 0.381126\n",
      "[10]\tvalid_0's multi_logloss: 0.351617\n",
      "[11]\tvalid_0's multi_logloss: 0.32518\n",
      "[12]\tvalid_0's multi_logloss: 0.303344\n",
      "[13]\tvalid_0's multi_logloss: 0.286267\n",
      "[14]\tvalid_0's multi_logloss: 0.267109\n",
      "[15]\tvalid_0's multi_logloss: 0.251422\n",
      "[16]\tvalid_0's multi_logloss: 0.240914\n",
      "[17]\tvalid_0's multi_logloss: 0.230984\n",
      "[18]\tvalid_0's multi_logloss: 0.220832\n",
      "[19]\tvalid_0's multi_logloss: 0.211619\n",
      "[20]\tvalid_0's multi_logloss: 0.204645\n",
      "[21]\tvalid_0's multi_logloss: 0.197972\n",
      "[22]\tvalid_0's multi_logloss: 0.192551\n",
      "[23]\tvalid_0's multi_logloss: 0.187974\n",
      "[24]\tvalid_0's multi_logloss: 0.183855\n",
      "[25]\tvalid_0's multi_logloss: 0.181657\n",
      "[26]\tvalid_0's multi_logloss: 0.1785\n",
      "[27]\tvalid_0's multi_logloss: 0.177106\n",
      "[28]\tvalid_0's multi_logloss: 0.174901\n",
      "[29]\tvalid_0's multi_logloss: 0.174139\n",
      "[30]\tvalid_0's multi_logloss: 0.172456\n",
      "[31]\tvalid_0's multi_logloss: 0.172201\n",
      "[32]\tvalid_0's multi_logloss: 0.170882\n",
      "[33]\tvalid_0's multi_logloss: 0.170504\n",
      "[34]\tvalid_0's multi_logloss: 0.168289\n",
      "[35]\tvalid_0's multi_logloss: 0.167896\n",
      "[36]\tvalid_0's multi_logloss: 0.166547\n",
      "[37]\tvalid_0's multi_logloss: 0.165416\n",
      "[38]\tvalid_0's multi_logloss: 0.165453\n",
      "[39]\tvalid_0's multi_logloss: 0.165249\n",
      "[40]\tvalid_0's multi_logloss: 0.165962\n",
      "[41]\tvalid_0's multi_logloss: 0.166398\n",
      "[42]\tvalid_0's multi_logloss: 0.1668\n",
      "[43]\tvalid_0's multi_logloss: 0.167419\n",
      "[44]\tvalid_0's multi_logloss: 0.167159\n",
      "[45]\tvalid_0's multi_logloss: 0.167484\n",
      "[46]\tvalid_0's multi_logloss: 0.168219\n",
      "[47]\tvalid_0's multi_logloss: 0.169168\n",
      "[48]\tvalid_0's multi_logloss: 0.170637\n",
      "[49]\tvalid_0's multi_logloss: 0.171687\n",
      "[50]\tvalid_0's multi_logloss: 0.17324\n",
      "[51]\tvalid_0's multi_logloss: 0.174366\n",
      "[52]\tvalid_0's multi_logloss: 0.176075\n",
      "[53]\tvalid_0's multi_logloss: 0.177206\n",
      "[54]\tvalid_0's multi_logloss: 0.179\n",
      "[55]\tvalid_0's multi_logloss: 0.18021\n",
      "[56]\tvalid_0's multi_logloss: 0.18206\n",
      "[57]\tvalid_0's multi_logloss: 0.183386\n",
      "[58]\tvalid_0's multi_logloss: 0.184644\n",
      "[59]\tvalid_0's multi_logloss: 0.186628\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 0.165249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_valid, y_valid = X[test_index] , y[test_index]\n",
    "    lgb_model = lgb.LGBMClassifier(early_stopping_round = 20, metric = 'multi_logloss')\n",
    "    lgb_model.fit(X_train, y_train,\n",
    "                 eval_set = [(X_valid, y_valid)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 정리\n",
    "**파라미터 참고문서**\n",
    "- [lightGBM parameters](https://lightgbm.readthedocs.io/en/latest/Parameters.html#objective)\n",
    "- [Laura++](https://sites.google.com/view/lauraepp/parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 파라미터 ####\n",
    "\n",
    "# 최대 깊이\n",
    "max_depth = -1\n",
    "\n",
    "# 하나의 Leaf가 가지고 있는 최소한의 관측치 수\n",
    "min_data_in_leaf = 20\n",
    "\n",
    "# column sampling ratio\n",
    "feature_fraction = 1 # .7 (typically)\n",
    "\n",
    "# row sampling ratio\n",
    "bagging_fraction = 1 # .7 (typically)\n",
    "\n",
    "# ratio of L1, L2 regularization\n",
    "lambda_l1 = 0\n",
    "lambda_l2 = 0\n",
    "\n",
    "# 범주형 변수가 있는 경우, 범주의 최대 개수 설정\n",
    "max_cat_threshold = 32\n",
    "\n",
    "# \n",
    "early_stopping_round = 'NULL'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Core parameter ####\n",
    "#### ############## ####\n",
    "\n",
    "task = 'train'\n",
    "#  'train'         , for training, \n",
    "#  'predict'       , for prediction, \n",
    "#  'convert_model' , for converting model file into if-else format, see more information in Convert Parameters\n",
    "#  'refit'         , for refitting existing models with new data, aliases: refit_tree\n",
    "#  'save_binary'   , load train (and validation) data then save dataset to binary file. Typical usage: save_binary first, then run multiple train tasks in parallel using the saved binary file\n",
    "# Note: can be used only in CLI version; for language-specific packages you can use the correspondent functions\n",
    "\n",
    "boosting = 'gdbt'\n",
    "#  'gbdt' , traditional Gradient Boosting Decision Tree, aliases: gbrt\n",
    "#  'rf'   , Random Forest, aliases: random_forest\n",
    "#  'dart' , Dropouts meet Multiple Additive Regression Trees\n",
    "#  'goss' , Gradient-based One-Side Sampling\n",
    "# Note: internally, LightGBM uses gbdt mode for the first 1 / learning_rate iterations\n",
    "\n",
    "application = 'regression'\n",
    "# objective\n",
    "# Go README.md\n",
    "\n",
    "num_iterations = 100 \n",
    "# typically n_iter >= 100\n",
    "# number of boosting iterations\n",
    "\n",
    "learning_rate = 0.1 \n",
    "# typically 0.1, 0.001, 0.0003\n",
    "# Go README.md\n",
    "\n",
    "num_leaves = 31 \n",
    "# max number of leaves in one tree\n",
    "\n",
    "\n",
    "\n",
    "#### Metric parameters ####\n",
    "#### ################# ####\n",
    "\n",
    "metric = ''\n",
    "# 'mean_absolute_error',     MAE\n",
    "# 'mean_squared_error',      MSE\n",
    "# 'root_mean_squared_error', RMSE\n",
    "# 'binary_logloss'\n",
    "# 'multi_logloss'\n",
    "# For more detail, Go README.md\n",
    "\n",
    "\n",
    "#### I/O parameters ####\n",
    "#### ############# ####\n",
    "\n",
    "max_bin = 32\n",
    "\n",
    "categorical_feature = ''\n",
    "# 범주형 변수의 index를 기입\n",
    "# categorical_feature = 0,1,2\n",
    "# categorical_feature = name: C0, C1, C2\n",
    "\n",
    "ignore_column = ''\n",
    "# 학습에서 무시할 변수 선택\n",
    "# 위와 동일한 방법 사용\n",
    "\n",
    "\n",
    "\n",
    "PARAMETERS = {\n",
    "    'max_depth' : max_depth,\n",
    "    'min_data_in_leaf' : min_data_in_leaf,\n",
    "    'feature_fraction' : feature_fraction,\n",
    "    'bagging_fraction' : bagging_fraction,\n",
    "    'early_stopping_round' : early_stopping_round,\n",
    "    'lambda_l1' : lambda_l1,\n",
    "    'lambda_l2' : lambda_l2,\n",
    "    'max_cat_threshold' : max_cat_threshold,\n",
    "    \n",
    "    'task' : task,\n",
    "    'boosting' : boosting,\n",
    "    'application' : application,\n",
    "    'num_iterations' : num_iterations,\n",
    "    'learning_rate' : learning_rate,\n",
    "    \n",
    "    'metric' : metric,\n",
    "    \n",
    "    'max_bin' : max_bin,\n",
    "    'categorical_feature' : categorical_feature,\n",
    "    'ignore_column' : ignore_column\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0  0]\n",
      " [ 8 18  0]\n",
      " [ 0  6 22]]\n",
      "[[21  8  0]\n",
      " [ 0 18  6]\n",
      " [ 0  0 22]]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(**parameters)\n",
    "    lgb_model.fit(X[train_index], y[train_index])\n",
    "    predictions = lgb_model.predict(X[train_index])\n",
    "    actuals = y[test_index]\n",
    "    print(confusion_matrix(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
