{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, ParameterGrid\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, f1_score\n",
    "from sklearn.datasets import load_iris, load_digits, load_boston\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rng = np.random.RandomState(950530)\n",
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "X = iris['data']\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(n_jobs=1)\n",
    "lgb_model.fit(X[train_index], y[train_index])\n",
    "predictions = lgb_model.predict(X[test_index])\n",
    "actuals = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(max_cat_group=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.LGBMClassifier(max_cat_group = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.992262\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.855017\n",
      "[3]\tvalid_0's multi_logloss: 0.746164\n",
      "[4]\tvalid_0's multi_logloss: 0.649684\n",
      "[5]\tvalid_0's multi_logloss: 0.572122\n",
      "[6]\tvalid_0's multi_logloss: 0.50741\n",
      "[7]\tvalid_0's multi_logloss: 0.451829\n",
      "[8]\tvalid_0's multi_logloss: 0.402324\n",
      "[9]\tvalid_0's multi_logloss: 0.365978\n",
      "[10]\tvalid_0's multi_logloss: 0.328674\n",
      "[11]\tvalid_0's multi_logloss: 0.30233\n",
      "[12]\tvalid_0's multi_logloss: 0.27372\n",
      "[13]\tvalid_0's multi_logloss: 0.249673\n",
      "[14]\tvalid_0's multi_logloss: 0.227833\n",
      "[15]\tvalid_0's multi_logloss: 0.213779\n",
      "[16]\tvalid_0's multi_logloss: 0.196155\n",
      "[17]\tvalid_0's multi_logloss: 0.18123\n",
      "[18]\tvalid_0's multi_logloss: 0.168856\n",
      "[19]\tvalid_0's multi_logloss: 0.157788\n",
      "[20]\tvalid_0's multi_logloss: 0.148908\n",
      "[21]\tvalid_0's multi_logloss: 0.14111\n",
      "[22]\tvalid_0's multi_logloss: 0.134441\n",
      "[23]\tvalid_0's multi_logloss: 0.12769\n",
      "[24]\tvalid_0's multi_logloss: 0.124757\n",
      "[25]\tvalid_0's multi_logloss: 0.12296\n",
      "[26]\tvalid_0's multi_logloss: 0.118302\n",
      "[27]\tvalid_0's multi_logloss: 0.116994\n",
      "[28]\tvalid_0's multi_logloss: 0.117123\n",
      "[29]\tvalid_0's multi_logloss: 0.113853\n",
      "[30]\tvalid_0's multi_logloss: 0.114123\n",
      "[31]\tvalid_0's multi_logloss: 0.113957\n",
      "[32]\tvalid_0's multi_logloss: 0.115572\n",
      "[33]\tvalid_0's multi_logloss: 0.113337\n",
      "[34]\tvalid_0's multi_logloss: 0.115247\n",
      "[35]\tvalid_0's multi_logloss: 0.116259\n",
      "[36]\tvalid_0's multi_logloss: 0.118311\n",
      "[37]\tvalid_0's multi_logloss: 0.117951\n",
      "[38]\tvalid_0's multi_logloss: 0.118604\n",
      "[39]\tvalid_0's multi_logloss: 0.118945\n",
      "[40]\tvalid_0's multi_logloss: 0.115808\n",
      "[41]\tvalid_0's multi_logloss: 0.115454\n",
      "[42]\tvalid_0's multi_logloss: 0.11463\n",
      "[43]\tvalid_0's multi_logloss: 0.11588\n",
      "[44]\tvalid_0's multi_logloss: 0.115487\n",
      "[45]\tvalid_0's multi_logloss: 0.115343\n",
      "[46]\tvalid_0's multi_logloss: 0.118421\n",
      "[47]\tvalid_0's multi_logloss: 0.11977\n",
      "[48]\tvalid_0's multi_logloss: 0.120265\n",
      "[49]\tvalid_0's multi_logloss: 0.122001\n",
      "[50]\tvalid_0's multi_logloss: 0.121542\n",
      "[51]\tvalid_0's multi_logloss: 0.120577\n",
      "[52]\tvalid_0's multi_logloss: 0.120646\n",
      "[53]\tvalid_0's multi_logloss: 0.118036\n",
      "[54]\tvalid_0's multi_logloss: 0.116567\n",
      "[55]\tvalid_0's multi_logloss: 0.116931\n",
      "[56]\tvalid_0's multi_logloss: 0.119528\n",
      "[57]\tvalid_0's multi_logloss: 0.119081\n",
      "[58]\tvalid_0's multi_logloss: 0.116675\n",
      "[59]\tvalid_0's multi_logloss: 0.114512\n",
      "[60]\tvalid_0's multi_logloss: 0.115748\n",
      "[61]\tvalid_0's multi_logloss: 0.113606\n",
      "[62]\tvalid_0's multi_logloss: 0.1189\n",
      "[63]\tvalid_0's multi_logloss: 0.120784\n",
      "[64]\tvalid_0's multi_logloss: 0.122018\n",
      "[65]\tvalid_0's multi_logloss: 0.123879\n",
      "[66]\tvalid_0's multi_logloss: 0.123445\n",
      "[67]\tvalid_0's multi_logloss: 0.123406\n",
      "[68]\tvalid_0's multi_logloss: 0.127197\n",
      "[69]\tvalid_0's multi_logloss: 0.129288\n",
      "[70]\tvalid_0's multi_logloss: 0.129063\n",
      "[71]\tvalid_0's multi_logloss: 0.134871\n",
      "[72]\tvalid_0's multi_logloss: 0.134626\n",
      "[73]\tvalid_0's multi_logloss: 0.134687\n",
      "[74]\tvalid_0's multi_logloss: 0.137048\n",
      "[75]\tvalid_0's multi_logloss: 0.137023\n",
      "[76]\tvalid_0's multi_logloss: 0.139524\n",
      "[77]\tvalid_0's multi_logloss: 0.141289\n",
      "[78]\tvalid_0's multi_logloss: 0.140627\n",
      "[79]\tvalid_0's multi_logloss: 0.140926\n",
      "[80]\tvalid_0's multi_logloss: 0.141228\n",
      "[81]\tvalid_0's multi_logloss: 0.142397\n",
      "[82]\tvalid_0's multi_logloss: 0.1416\n",
      "[83]\tvalid_0's multi_logloss: 0.14272\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's multi_logloss: 0.113337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(early_stopping_round=50, metric='multi_logloss')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "lgb_model = lgb.LGBMClassifier(early_stopping_round = 50, metric = 'multi_logloss')\n",
    "lgb_model.fit(X_train, y_train,\n",
    "             eval_set = [(X_valid, y_valid)]) # NEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.95551\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.816281\n",
      "[3]\tvalid_0's multi_logloss: 0.708683\n",
      "[4]\tvalid_0's multi_logloss: 0.620288\n",
      "[5]\tvalid_0's multi_logloss: 0.546995\n",
      "[6]\tvalid_0's multi_logloss: 0.483309\n",
      "[7]\tvalid_0's multi_logloss: 0.432137\n",
      "[8]\tvalid_0's multi_logloss: 0.385391\n",
      "[9]\tvalid_0's multi_logloss: 0.348436\n",
      "[10]\tvalid_0's multi_logloss: 0.320539\n",
      "[11]\tvalid_0's multi_logloss: 0.294368\n",
      "[12]\tvalid_0's multi_logloss: 0.268866\n",
      "[13]\tvalid_0's multi_logloss: 0.247843\n",
      "[14]\tvalid_0's multi_logloss: 0.229687\n",
      "[15]\tvalid_0's multi_logloss: 0.21402\n",
      "[16]\tvalid_0's multi_logloss: 0.20124\n",
      "[17]\tvalid_0's multi_logloss: 0.186713\n",
      "[18]\tvalid_0's multi_logloss: 0.176332\n",
      "[19]\tvalid_0's multi_logloss: 0.166914\n",
      "[20]\tvalid_0's multi_logloss: 0.159202\n",
      "[21]\tvalid_0's multi_logloss: 0.153756\n",
      "[22]\tvalid_0's multi_logloss: 0.146985\n",
      "[23]\tvalid_0's multi_logloss: 0.142102\n",
      "[24]\tvalid_0's multi_logloss: 0.137605\n",
      "[25]\tvalid_0's multi_logloss: 0.134159\n",
      "[26]\tvalid_0's multi_logloss: 0.131993\n",
      "[27]\tvalid_0's multi_logloss: 0.129672\n",
      "[28]\tvalid_0's multi_logloss: 0.127285\n",
      "[29]\tvalid_0's multi_logloss: 0.126657\n",
      "[30]\tvalid_0's multi_logloss: 0.12476\n",
      "[31]\tvalid_0's multi_logloss: 0.124205\n",
      "[32]\tvalid_0's multi_logloss: 0.122879\n",
      "[33]\tvalid_0's multi_logloss: 0.122632\n",
      "[34]\tvalid_0's multi_logloss: 0.123365\n",
      "[35]\tvalid_0's multi_logloss: 0.123504\n",
      "[36]\tvalid_0's multi_logloss: 0.12238\n",
      "[37]\tvalid_0's multi_logloss: 0.120717\n",
      "[38]\tvalid_0's multi_logloss: 0.119646\n",
      "[39]\tvalid_0's multi_logloss: 0.118839\n",
      "[40]\tvalid_0's multi_logloss: 0.118326\n",
      "[41]\tvalid_0's multi_logloss: 0.117972\n",
      "[42]\tvalid_0's multi_logloss: 0.117551\n",
      "[43]\tvalid_0's multi_logloss: 0.117575\n",
      "[44]\tvalid_0's multi_logloss: 0.116775\n",
      "[45]\tvalid_0's multi_logloss: 0.115575\n",
      "[46]\tvalid_0's multi_logloss: 0.114493\n",
      "[47]\tvalid_0's multi_logloss: 0.113895\n",
      "[48]\tvalid_0's multi_logloss: 0.112918\n",
      "[49]\tvalid_0's multi_logloss: 0.112017\n",
      "[50]\tvalid_0's multi_logloss: 0.110679\n",
      "[51]\tvalid_0's multi_logloss: 0.109447\n",
      "[52]\tvalid_0's multi_logloss: 0.110191\n",
      "[53]\tvalid_0's multi_logloss: 0.109383\n",
      "[54]\tvalid_0's multi_logloss: 0.1099\n",
      "[55]\tvalid_0's multi_logloss: 0.108386\n",
      "[56]\tvalid_0's multi_logloss: 0.108017\n",
      "[57]\tvalid_0's multi_logloss: 0.108731\n",
      "[58]\tvalid_0's multi_logloss: 0.108124\n",
      "[59]\tvalid_0's multi_logloss: 0.10875\n",
      "[60]\tvalid_0's multi_logloss: 0.109129\n",
      "[61]\tvalid_0's multi_logloss: 0.108193\n",
      "[62]\tvalid_0's multi_logloss: 0.108072\n",
      "[63]\tvalid_0's multi_logloss: 0.108744\n",
      "[64]\tvalid_0's multi_logloss: 0.108641\n",
      "[65]\tvalid_0's multi_logloss: 0.108814\n",
      "[66]\tvalid_0's multi_logloss: 0.108956\n",
      "[67]\tvalid_0's multi_logloss: 0.108912\n",
      "[68]\tvalid_0's multi_logloss: 0.109643\n",
      "[69]\tvalid_0's multi_logloss: 0.109604\n",
      "[70]\tvalid_0's multi_logloss: 0.110665\n",
      "[71]\tvalid_0's multi_logloss: 0.110508\n",
      "[72]\tvalid_0's multi_logloss: 0.11126\n",
      "[73]\tvalid_0's multi_logloss: 0.111105\n",
      "[74]\tvalid_0's multi_logloss: 0.111882\n",
      "[75]\tvalid_0's multi_logloss: 0.112297\n",
      "[76]\tvalid_0's multi_logloss: 0.111475\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_logloss: 0.108017\n",
      "\n",
      "[1]\tvalid_0's multi_logloss: 0.951932\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.819339\n",
      "[3]\tvalid_0's multi_logloss: 0.714381\n",
      "[4]\tvalid_0's multi_logloss: 0.62516\n",
      "[5]\tvalid_0's multi_logloss: 0.557524\n",
      "[6]\tvalid_0's multi_logloss: 0.500951\n",
      "[7]\tvalid_0's multi_logloss: 0.457237\n",
      "[8]\tvalid_0's multi_logloss: 0.416388\n",
      "[9]\tvalid_0's multi_logloss: 0.381126\n",
      "[10]\tvalid_0's multi_logloss: 0.351617\n",
      "[11]\tvalid_0's multi_logloss: 0.32518\n",
      "[12]\tvalid_0's multi_logloss: 0.303344\n",
      "[13]\tvalid_0's multi_logloss: 0.286267\n",
      "[14]\tvalid_0's multi_logloss: 0.267109\n",
      "[15]\tvalid_0's multi_logloss: 0.251422\n",
      "[16]\tvalid_0's multi_logloss: 0.240914\n",
      "[17]\tvalid_0's multi_logloss: 0.230984\n",
      "[18]\tvalid_0's multi_logloss: 0.220832\n",
      "[19]\tvalid_0's multi_logloss: 0.211619\n",
      "[20]\tvalid_0's multi_logloss: 0.204645\n",
      "[21]\tvalid_0's multi_logloss: 0.197972\n",
      "[22]\tvalid_0's multi_logloss: 0.192551\n",
      "[23]\tvalid_0's multi_logloss: 0.187974\n",
      "[24]\tvalid_0's multi_logloss: 0.183855\n",
      "[25]\tvalid_0's multi_logloss: 0.181657\n",
      "[26]\tvalid_0's multi_logloss: 0.1785\n",
      "[27]\tvalid_0's multi_logloss: 0.177106\n",
      "[28]\tvalid_0's multi_logloss: 0.174901\n",
      "[29]\tvalid_0's multi_logloss: 0.174139\n",
      "[30]\tvalid_0's multi_logloss: 0.172456\n",
      "[31]\tvalid_0's multi_logloss: 0.172201\n",
      "[32]\tvalid_0's multi_logloss: 0.170882\n",
      "[33]\tvalid_0's multi_logloss: 0.170504\n",
      "[34]\tvalid_0's multi_logloss: 0.168289\n",
      "[35]\tvalid_0's multi_logloss: 0.167896\n",
      "[36]\tvalid_0's multi_logloss: 0.166547\n",
      "[37]\tvalid_0's multi_logloss: 0.165416\n",
      "[38]\tvalid_0's multi_logloss: 0.165453\n",
      "[39]\tvalid_0's multi_logloss: 0.165249\n",
      "[40]\tvalid_0's multi_logloss: 0.165962\n",
      "[41]\tvalid_0's multi_logloss: 0.166398\n",
      "[42]\tvalid_0's multi_logloss: 0.1668\n",
      "[43]\tvalid_0's multi_logloss: 0.167419\n",
      "[44]\tvalid_0's multi_logloss: 0.167159\n",
      "[45]\tvalid_0's multi_logloss: 0.167484\n",
      "[46]\tvalid_0's multi_logloss: 0.168219\n",
      "[47]\tvalid_0's multi_logloss: 0.169168\n",
      "[48]\tvalid_0's multi_logloss: 0.170637\n",
      "[49]\tvalid_0's multi_logloss: 0.171687\n",
      "[50]\tvalid_0's multi_logloss: 0.17324\n",
      "[51]\tvalid_0's multi_logloss: 0.174366\n",
      "[52]\tvalid_0's multi_logloss: 0.176075\n",
      "[53]\tvalid_0's multi_logloss: 0.177206\n",
      "[54]\tvalid_0's multi_logloss: 0.179\n",
      "[55]\tvalid_0's multi_logloss: 0.18021\n",
      "[56]\tvalid_0's multi_logloss: 0.18206\n",
      "[57]\tvalid_0's multi_logloss: 0.183386\n",
      "[58]\tvalid_0's multi_logloss: 0.184644\n",
      "[59]\tvalid_0's multi_logloss: 0.186628\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 0.165249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_valid, y_valid = X[test_index] , y[test_index]\n",
    "    lgb_model = lgb.LGBMClassifier(early_stopping_round = 20, metric = 'multi_logloss')\n",
    "    lgb_model.fit(X_train, y_train,\n",
    "                 eval_set = [(X_valid, y_valid)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 정리\n",
    "**파라미터 참고문서**\n",
    "- [lightGBM parameters](https://lightgbm.readthedocs.io/en/latest/Parameters.html#objective)\n",
    "- [Laura++](https://sites.google.com/view/lauraepp/parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 파라미터 ####\n",
    "\n",
    "# 최대 깊이\n",
    "max_depth = -1\n",
    "\n",
    "# 하나의 Leaf가 가지고 있는 최소한의 관측치 수\n",
    "min_data_in_leaf = 20\n",
    "\n",
    "# column sampling ratio\n",
    "feature_fraction = 1 # .7 (typically)\n",
    "\n",
    "# row sampling ratio\n",
    "bagging_fraction = 1 # .7 (typically)\n",
    "\n",
    "# ratio of L1, L2 regularization\n",
    "lambda_l1 = 0\n",
    "lambda_l2 = 0\n",
    "\n",
    "# 범주형 변수가 있는 경우, 범주의 최대 개수 설정\n",
    "max_cat_threshold = 32\n",
    "\n",
    "# \n",
    "early_stopping_round = 'NULL'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Core parameter ####\n",
    "#### ############## ####\n",
    "\n",
    "task = 'train'\n",
    "#  'train'         , for training, \n",
    "#  'predict'       , for prediction, \n",
    "#  'convert_model' , for converting model file into if-else format, see more information in Convert Parameters\n",
    "#  'refit'         , for refitting existing models with new data, aliases: refit_tree\n",
    "#  'save_binary'   , load train (and validation) data then save dataset to binary file. Typical usage: save_binary first, then run multiple train tasks in parallel using the saved binary file\n",
    "# Note: can be used only in CLI version; for language-specific packages you can use the correspondent functions\n",
    "\n",
    "boosting = 'gdbt'\n",
    "#  'gbdt' , traditional Gradient Boosting Decision Tree, aliases: gbrt\n",
    "#  'rf'   , Random Forest, aliases: random_forest\n",
    "#  'dart' , Dropouts meet Multiple Additive Regression Trees\n",
    "#  'goss' , Gradient-based One-Side Sampling\n",
    "# Note: internally, LightGBM uses gbdt mode for the first 1 / learning_rate iterations\n",
    "\n",
    "application = 'regression'\n",
    "# objective\n",
    "# Go README.md\n",
    "\n",
    "num_iterations = 100 \n",
    "# typically n_iter >= 100\n",
    "# number of boosting iterations\n",
    "\n",
    "learning_rate = 0.1 \n",
    "# typically 0.1, 0.001, 0.0003\n",
    "# Go README.md\n",
    "\n",
    "num_leaves = 31 \n",
    "# max number of leaves in one tree\n",
    "\n",
    "\n",
    "\n",
    "#### Metric parameters ####\n",
    "#### ################# ####\n",
    "\n",
    "metric = ''\n",
    "# 'mean_absolute_error',     MAE\n",
    "# 'mean_squared_error',      MSE\n",
    "# 'root_mean_squared_error', RMSE\n",
    "# 'binary_logloss'\n",
    "# 'multi_logloss'\n",
    "# For more detail, Go README.md\n",
    "\n",
    "\n",
    "#### I/O parameters ####\n",
    "#### ############# ####\n",
    "\n",
    "max_bin = 32\n",
    "\n",
    "categorical_feature = ''\n",
    "# 범주형 변수의 index를 기입\n",
    "# categorical_feature = 0,1,2\n",
    "# categorical_feature = name: C0, C1, C2\n",
    "\n",
    "ignore_column = ''\n",
    "# 학습에서 무시할 변수 선택\n",
    "# 위와 동일한 방법 사용\n",
    "\n",
    "\n",
    "\n",
    "PARAMETERS = {\n",
    "    'max_depth' : max_depth,\n",
    "    'min_data_in_leaf' : min_data_in_leaf,\n",
    "    'feature_fraction' : feature_fraction,\n",
    "    'bagging_fraction' : bagging_fraction,\n",
    "    'early_stopping_round' : early_stopping_round,\n",
    "    'lambda_l1' : lambda_l1,\n",
    "    'lambda_l2' : lambda_l2,\n",
    "    'max_cat_threshold' : max_cat_threshold,\n",
    "    \n",
    "    'task' : task,\n",
    "    'boosting' : boosting,\n",
    "    'application' : application,\n",
    "    'num_iterations' : num_iterations,\n",
    "    'learning_rate' : learning_rate,\n",
    "    \n",
    "    'metric' : metric,\n",
    "    \n",
    "    'max_bin' : max_bin,\n",
    "    'categorical_feature' : categorical_feature,\n",
    "    'ignore_column' : ignore_column\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0  0]\n",
      " [ 8 18  0]\n",
      " [ 0  6 22]]\n",
      "[[21  8  0]\n",
      " [ 0 18  6]\n",
      " [ 0  0 22]]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(**parameters)\n",
    "    lgb_model.fit(X[train_index], y[train_index])\n",
    "    predictions = lgb_model.predict(X[train_index])\n",
    "    actuals = y[test_index]\n",
    "    print(confusion_matrix(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
