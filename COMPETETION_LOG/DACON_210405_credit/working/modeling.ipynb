{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, log_loss, f1_score\n",
    "\n",
    "import random\n",
    "from math import floor\n",
    "from scipy.stats import mode, scoreatpercentile\n",
    "\n",
    "print(\"Seaborn version : \", sns.__version__)\n",
    "sns.set()\n",
    "#sns.set_style('whitegrid')\n",
    "sns.set_color_codes()\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "\n",
    "\n",
    "# upload data\n",
    "train = pd.read_csv('/Users/gangtaro/competition_data/DACON/14thMonthlyDacon/open/train.csv',\n",
    "                   index_col=0)\n",
    "test = pd.read_csv('/Users/gangtaro/competition_data/DACON/14thMonthlyDacon/open/test.csv',\n",
    "                  index_col=0)\n",
    "submit = pd.read_csv('/Users/gangtaro/competition_data/DACON/14thMonthlyDacon/open/sample_submission.csv')\n",
    "\n",
    "\n",
    "for df in [train, test]:\n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['gender', 'car', 'reality', 'work_phone', 'phone', 'email']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    df.drop('FLAG_MOBIL', axis = 1, inplace = True)\n",
    "    df['adj_DAYS_EMPLOYED_replace_0'] = -df.DAYS_EMPLOYED.replace({365243 : 0})\n",
    "    df['DAYS_EMPLOYED_missing'] = (df.DAYS_EMPLOYED == 365243).astype('int')\n",
    "    df['adj_begin_month'] = -df.begin_month\n",
    "    df['adj_income_type'] = df.income_type\n",
    "    df.loc[df.income_type == 'Student', 'adj_income_type'] = 'Working'\n",
    "    df['adj_edu_type'] = df.edu_type \n",
    "    df.loc[df.edu_type == 'Academic degree', 'adj_edu_type'] = 'Higher education'\n",
    "    df['adj_family_type'] = df['family_type']\n",
    "    df['adj_family_type'].loc[(df.family_type == 'Single / not married')&(df.family_size - df.child_num == 2)] = 'Married'\n",
    "    df['exp_num'] = 0\n",
    "    df['exp_num'].loc[df.family_type == 'Married'] = 2\n",
    "    df['exp_num'].loc[df.family_type == 'Civil marriage'] = 2\n",
    "    df['exp_num'].loc[df.family_type == 'Separated'] = 1\n",
    "    df['exp_num'].loc[df.family_type == 'Single / not married'] = 1\n",
    "    df['exp_num'].loc[df.family_type == 'Widow'] = 1\n",
    "    df['odd_family_size'] = 0\n",
    "    df['odd_family_size'].loc[(df.family_size - df.child_num) != df.exp_num] = 1\n",
    "    df['_single_parents'] = ((df.family_type == 'Single / not married')&(df.child_num != 0)).astype('int')\n",
    "    df['_single_live'] = (df.family_size == 1).astype('int')\n",
    "    df['adj_occyp_type'] = df.occyp_type.fillna('missing')\n",
    "    df['_missing_occyp_type'] = df.occyp_type.isna().astype('int')\n",
    "    df.loc[(df.DAYS_EMPLOYED == 365243)&(df.occyp_type.isna()), 'adj_occyp_type'] = 'inoccyp'\n",
    "    df.loc[(df.DAYS_EMPLOYED != 365243)&(df.occyp_type.isna()), 'adj_occyp_type'] = 'non_enter'\n",
    "    df['_age'] = -df.DAYS_BIRTH/365.25\n",
    "\n",
    "    df['ID'] = \\\n",
    "    df['gender'].astype('str') + \\\n",
    "    df['car'].astype('str') + \\\n",
    "    df['reality'].astype('str') + '_' + \\\n",
    "    df['child_num'].astype('str') + '_' + \\\n",
    "    df['income_total'].astype('str') + '_' + \\\n",
    "    df['income_type'].astype('str') + '_' + \\\n",
    "    df['family_type'].astype('str') + '_' + \\\n",
    "    df['house_type'].astype('str') + '_' + \\\n",
    "    df['phone'].astype('str') + '_' + \\\n",
    "    df['email'].astype('str') + '_' + \\\n",
    "    df['family_size'].astype('str') + '_' + \\\n",
    "    df['DAYS_BIRTH'].astype('str') + '_' + \\\n",
    "    df['DAYS_EMPLOYED'].astype('str') + '_' + \\\n",
    "    df['occyp_type'].astype('str') \n",
    "    \n",
    "    df['_card_num'] = df.groupby('ID').ID.transform(len)\n",
    "    \n",
    "    df['adj_begin_month'] = -df.begin_month\n",
    "    df['_begin_month_max'] = df.groupby('ID').adj_begin_month.transform(max)\n",
    "    df['_begin_month_mean'] = df.groupby('ID').adj_begin_month.transform(np.mean)\n",
    "    df['_begin_month_min'] = df.groupby('ID').adj_begin_month.transform(min)\n",
    "    \n",
    "\n",
    "personal_info = train.drop(['credit', 'begin_month'], axis = 1).drop_duplicates(subset=\"ID\", keep='first', inplace=False, ignore_index=True)\n",
    "personal_info_test = pd.concat([train.drop(['credit'], axis = 1), test]).drop(['begin_month'], axis = 1).drop_duplicates(subset=\"ID\", keep='first', inplace=False, ignore_index=True)\n",
    "\n",
    "for personal_df in [personal_info, personal_info_test]:\n",
    "    ####### 양육비 변수 ######\n",
    "    child_fee = (personal_df.income_total/personal_df.family_size)[(personal_df._age > 33) & (personal_df._age < 37) & (personal_df.child_num == 1)].mean()\n",
    "\n",
    "    def child_fee_age_weights(x) : \n",
    "        from scipy.stats import norm\n",
    "        sd = personal_df._age.std()\n",
    "        return norm(35, scale = sd).pdf(x) / norm(35, scale = sd).pdf(35)\n",
    "    personal_df['child_fees'] = (np.log(personal_df.child_num + 1)/np.log(2)) * (child_fee) * personal_df._age.apply(child_fee_age_weights)\n",
    "\n",
    "    ####### 차유지비 변수 ######\n",
    "    personal_df.income_total.median()*0.1\n",
    "    def car_weight(x):\n",
    "        _med = personal_df.income_total.median()\n",
    "        _max = personal_df.income_total.max()\n",
    "        if x < _med : \n",
    "            return 1\n",
    "        else:\n",
    "            return 1+(x-_med)/(_max-_med)*5\n",
    "    personal_df['car_fees'] = personal_df.income_total.median()*0.1*personal_df.car*personal_df.income_total.apply(car_weight)\n",
    "\n",
    "    ####### 여유금 변수 ######\n",
    "    personal_df['_save_income'] = personal_df.income_total - personal_df.child_fees - personal_df.car_fees\n",
    "\n",
    "    ####### 능력 변수 ######\n",
    "    personal_df['_ability_income_per_age'] = 0\n",
    "    personal_df['_ability_employ_per_age'] = 0\n",
    "    personal_df['_ability_income_per_emp'] = 0\n",
    "    for i in range(len(personal_df)) : \n",
    "        L_age = personal_df._age[i] - 3\n",
    "        R_age = personal_df._age[i] + 3\n",
    "        _gen = personal_df.gender[i]\n",
    "        _ages_df = personal_df[['income_total', 'adj_DAYS_EMPLOYED_replace_0']][(personal_df._age > L_age) & (personal_df._age < R_age) & (personal_df.gender == _gen)]\n",
    "        _med_income = _ages_df['income_total'].median()\n",
    "        _std_income = _ages_df['income_total'].std()\n",
    "        _med_employ = _ages_df['adj_DAYS_EMPLOYED_replace_0'].median()\n",
    "        _std_employ = _ages_df['adj_DAYS_EMPLOYED_replace_0'].std()\n",
    "        _n_df       = _ages_df.shape[0]\n",
    "        personal_df.loc[i, '_ability_income_per_age'] = (personal_df.income_total.iloc[i] - _med_income) / (_std_income /np.sqrt(_n_df))\n",
    "        personal_df.loc[i, '_ability_employ_per_age'] = (personal_df.adj_DAYS_EMPLOYED_replace_0.iloc[i] - _med_employ) / (_std_employ/np.sqrt(_n_df))\n",
    "\n",
    "        if personal_df.adj_DAYS_EMPLOYED_replace_0.iloc[i] != 0:    \n",
    "            L_emp = personal_df.adj_DAYS_EMPLOYED_replace_0 - 365\n",
    "            R_emp = personal_df.adj_DAYS_EMPLOYED_replace_0 + 365\n",
    "            _emps_df = personal_df.income_total[(personal_df.adj_DAYS_EMPLOYED_replace_0 > L_emp)&(personal_df.adj_DAYS_EMPLOYED_replace_0 < R_emp)]\n",
    "            _med = _emps_df.median()\n",
    "            _std = _emps_df.std()\n",
    "            personal_df.loc[i, '_ability_income_per_emp'] = (personal_df.income_total.iloc[i] - _med)/(_std/np.sqrt(_n_df))\n",
    "\n",
    "train  = pd.merge(train, personal_info[['ID', '_save_income', 'child_fees', 'car_fees', '_ability_income_per_age', '_ability_employ_per_age', '_ability_income_per_emp']], on = 'ID', how = 'left')\n",
    "test = pd.merge(test, personal_info_test[['ID', '_save_income', 'child_fees', 'car_fees', '_ability_income_per_age', '_ability_employ_per_age', '_ability_income_per_emp']], on = 'ID', how = 'left')\n",
    "\n",
    "\n",
    "for df in [train, test]:\n",
    "    #카드 소유자가 가진 카드들에 할당할 수 있는 금액을 고려\n",
    "    df['_income_per_cards']  = df.income_total / np.log(1+df._card_num)\n",
    "    df['_save_per_cards']    = df._save_income / np.log(1+df._card_num)\n",
    "\n",
    "    # 가족들에게 할당 될 수 있는 소득 그리고 여유자금을 고려\n",
    "    df['_income_per_family'] = df.income_total / df.family_size\n",
    "    df['_save_per_family']   = df._save_income / df.family_size\n",
    "    \n",
    "    df['_age'] = df['_age'].apply(lambda x: floor(x))\n",
    "    df['adj_DAYS_EMPLOYED_mm'] = df['adj_DAYS_EMPLOYED_replace_0'].apply(lambda x: floor(x/30))\n",
    "    df['adj_DAYS_EMPLOYED_yy'] = df['adj_DAYS_EMPLOYED_replace_0'].apply(lambda x: floor(x/365.25))\n",
    "    df['log_income_total'] = df['income_total'].apply(lambda x: np.log(1+x))\n",
    "    \n",
    "features = ['gender', 'car', 'reality', 'child_num', 'adj_income_type', 'adj_edu_type', \n",
    "            'adj_family_type', 'house_type', '_age', 'adj_DAYS_EMPLOYED_replace_0', 'adj_DAYS_EMPLOYED_mm', 'adj_DAYS_EMPLOYED_yy',\n",
    "            'adj_begin_month', 'work_phone', 'phone', 'email', 'adj_occyp_type', \n",
    "            'ID', '_begin_month_min',\n",
    "            '_save_income','_income_per_family', 'log_income_total',\n",
    "            '_ability_income_per_age']\n",
    "\n",
    "numerical_feats = train[features].dtypes[train[features].dtypes != \"object\"].index.tolist()\n",
    "#numerical_feats.remove('credit')\n",
    "print(\"Number of Numerical features: \", len(numerical_feats))\n",
    "\n",
    "categorical_feats = train[features].dtypes[train[features].dtypes == \"object\"].index.tolist()\n",
    "print(\"Number of Categorical features: \", len(categorical_feats))\n",
    "\n",
    "\n",
    "target = 'credit'\n",
    "X = train.drop(target, axis=1)[features]\n",
    "y = train[target]\n",
    "X_test = test[features]\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "      \"random_state\":42,\n",
    "      'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "      'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "      \"n_estimators\":trial.suggest_int(\"n_estimators\", 1000, 10000),\n",
    "      \"max_depth\":trial.suggest_int(\"max_depth\", 4, 16),\n",
    "      'random_strength' :trial.suggest_int('random_strength', 0, 100),\n",
    "      \"colsample_bylevel\":trial.suggest_float(\"colsample_bylevel\", 0.4, 1.0),\n",
    "      \"l2_leaf_reg\":trial.suggest_float(\"l2_leaf_reg\",1e-8,3e-5),\n",
    "      \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "      \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "      'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "    }\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "    cat_features = categorical_feats + ['gender', 'car', 'reality', 'phone', 'email', 'work_phone']\n",
    "    cat = CatBoostClassifier(**param)\n",
    "    cat.fit(X_train, y_train,\n",
    "          eval_set=[(X_train, y_train), (X_valid,y_valid)],\n",
    "          early_stopping_rounds=35,cat_features=cat_features,\n",
    "          verbose=100)\n",
    "    cat_pred = cat.predict_proba(X_valid)\n",
    "    log_score = log_loss(y_valid, cat_pred)\n",
    "\n",
    "    return log_score\n",
    "\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name = 'cat_parameter_opt',\n",
    "    direction = 'minimize',\n",
    "    sampler = sampler,\n",
    ")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(\"Best Score:\",study.best_value)\n",
    "print(\"Best trial\",study.best_trial.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
