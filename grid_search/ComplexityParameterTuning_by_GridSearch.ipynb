{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고\n",
    "**사용한 모델**\n",
    "- Logistic Regression (로지스틱 모델) \n",
    "- Decision Tree (의사결정나무 모델)\n",
    "- Multi-layer Perceptron classifier (다중 레이어 신경망 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 평가 지표 => f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Hyper parameter tuning tool: Grid Search => Parameter Grid\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "data from [here-> http://archive.ics.uci.edu](http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = 'http://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
    "df = pd.read_csv(path_data, header = None)\n",
    "\n",
    "# set columns name\n",
    "df.columns = ['Band'+str(i) for i in range(1, 61)] + ['Y']\n",
    "\n",
    "# View the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징 열과 라벨 분리\n",
    "X = df.drop('Y', axis = 1)\n",
    "Y = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터와 평가 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 60)\n",
      "(52, 60)\n"
     ]
    }
   ],
   "source": [
    "print(Train_X.shape) # 샘플 156개, 특징 60개 => 단순한 모델 필요(일반적으로)\n",
    "print(Test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    81\n",
      " 1    75\n",
      "Name: Y, dtype: int64\n",
      "-1    30\n",
      " 1    22\n",
      "Name: Y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 라벨의 카테고리 빈도 확인 => 일반적인 비율\n",
    "print(Train_Y.value_counts())\n",
    "print(Test_Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨을 분석 모델에 포함시키기 위해 \n",
    "# int로 변경\n",
    "Train_Y.replace({\"M\":-1, \"R\":1}, inplace = True)\n",
    "Test_Y.replace({\"M\":-1, \"R\":1}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Parameter tuning\n",
    "\n",
    "### [Case 1] Logistic Regression (로지스틱 회귀)\n",
    "- 복잡도 파라미터가 1개\n",
    "- 단순함\n",
    "- 우연성 내제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction to Hyper parameter of Logistic Reg.**\n",
    "- **C** : float, default=1.0\n",
    "    Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.  \n",
    "    \n",
    "    복잡도와 반비례 관계, 회귀계수의 크기 조절하는 값.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_model_test(C):\n",
    "    \n",
    "    # random_state도 조금은 여러번 수행해봐야함\n",
    "    model = LogisticRegression(\n",
    "        C = C, # 복잡도 파라미터, \n",
    "        max_iter = 100000, # 단순한 모델 => max_iter 크게해도 좋다.\n",
    "        random_state = 10) # 여러번 수행하는 것이 좋다.\n",
    "    model.fit(Train_X, Train_Y) \n",
    "    pred_Y = model.predict(Test_X)\n",
    "    \n",
    "    return f1_score(Test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1:  \t0.7727272727272727\n",
      "C = 0.3:  \t0.8085106382978724\n",
      "C = 0.5:  \t0.7916666666666666\n",
      "C = 1:  \t0.7916666666666666\n",
      "C = 5:  \t0.8260869565217391\n",
      "C = 10:  \t0.8333333333333333\n",
      "C = 30:  \t0.8333333333333333\n",
      "C = 50:  \t0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 넓은 범위에서 먼저 탐색\n",
    "C_list = [0.1, 0.3, 0.5, 1, 5, 10, 30, 50]\n",
    "\n",
    "for C in C_list : \n",
    "    print('C = {}:  \\t{}'.format(C, LR_model_test(C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.1 < C < 50 은 범위가 더 넓다.  \n",
    "따라서 0.1 < C < 1 에서 국소적으로 다시 탐색\n",
    "\n",
    "ParameterGrid 방법으로 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.17346938775510207, 'max_iter': 100000, 'random_state': 10} 0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 그리드 설정\n",
    "LR_parameter_grid = ParameterGrid({\"C\":np.linspace(0.1, 1, 50),\n",
    "                                  \"max_iter\":[100000],\n",
    "                                  \"random_state\":[10]})\n",
    "\n",
    "# 파라미터 튜닝 수행 \n",
    "best_score = -1\n",
    "for parameter in LR_parameter_grid:\n",
    "    model = LR(**parameter).fit(Train_X, Train_Y)\n",
    "    pred_Y = model.predict(Test_X)\n",
    "    score = f1_score(Test_Y, pred_Y)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameter = parameter\n",
    "\n",
    "print(best_parameter, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Case 2] Decision Tree (의사 결정 나무)\n",
    "- 복잡도 파라미터가 2개\n",
    "- 단순함\n",
    "- 우연성 거의 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction to Hyper parameter of <u>Decision Tree<u/>**\n",
    "- **max_depth** : int, default=None  \n",
    "    The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "    \n",
    "    복잡도와 **비례**, Tree 모델의 깊이, 과적합을 피하기 위해 보통 **4**이하로 설정\n",
    "    \n",
    "    \n",
    "- **min_samples_leaf** : int or float, default=2  \n",
    "    The minimum number of samples required to split an internal node:\n",
    "\n",
    "    If int, then consider min_samples_split as the minimum number.\n",
    "If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.\n",
    "    \n",
    "    복잡도와 **반비례**, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTC_model_test(max_depth, min_samples_leaf):\n",
    "    \n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth = max_depth, \n",
    "        min_samples_leaf = min_samples_leaf)\n",
    "    \n",
    "    model.fit(Train_X, Train_Y) \n",
    "    pred_Y = model.predict(Test_X)\n",
    "    \n",
    "    return f1_score(Test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-1:0.6976744186046512\n",
      "3-2:0.7727272727272727\n",
      "3-3:0.7555555555555555\n",
      "6-1:0.6938775510204083\n",
      "6-2:0.7500000000000001\n",
      "6-3:0.7058823529411765\n",
      "9-1:0.7083333333333333\n",
      "9-2:0.7083333333333333\n",
      "9-3:0.7200000000000001\n",
      "12-1:0.7346938775510203\n",
      "12-2:0.6938775510204083\n",
      "12-3:0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "# 넓은 범위에서 선 탐색\n",
    "for max_depth in [3, 6, 9, 12]:\n",
    "    for min_samples_leaf in [1, 2, 3]:\n",
    "        score = DTC_model_test(max_depth = max_depth, min_samples_leaf = min_samples_leaf)\n",
    "        print(\"{}-{}:{}\".format(max_depth, min_samples_leaf, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max depth가 크고 (복잡도 증가) min_samples_leaf가 큰 경우 (복잡도 감소) 좋은 성능이 나옴을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_leaf': 2} 0.7500000000000001\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 그리드 설정\n",
    "DTC_parameter_grid = ParameterGrid({\"max_depth\": np.arange(6, 15),\n",
    "                                  \"min_samples_leaf\": np.arange(2, 5)})\n",
    "\n",
    "# 파라미터 튜닝 수행 \n",
    "best_score = -1\n",
    "for parameter in DTC_parameter_grid:\n",
    "    model = DecisionTreeClassifier(**parameter).fit(Train_X, Train_Y)\n",
    "    pred_Y = model.predict(Test_X)\n",
    "    score = f1_score(Test_Y, pred_Y)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameter = parameter\n",
    "\n",
    "print(best_parameter, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Case 3] Multi-layer Perceptron classifier (다중 레이어 <u>신경망</u> 모델)\n",
    "- 복잡도 파라미터가 1개 -> 은닉층을 튜플 단위로 1개로 고려\n",
    "- 복잡함\n",
    "- 우연성 내제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_model_test(hidden_layer_sizes):\n",
    "    \n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes = hidden_layer_sizes, \n",
    "        random_state = 12)\n",
    "    \n",
    "    model.fit(Train_X, Train_Y) \n",
    "    pred_Y = model.predict(Test_X)\n",
    "    \n",
    "    return f1_score(Test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer sizes : (5,),\t  score : 0.5945945945945945\n",
      "hidden layer sizes : (10,),\t  score : 0.8444444444444444\n",
      "hidden layer sizes : (3, 3),\t  score : 0.4571428571428572\n",
      "hidden layer sizes : (5, 5),\t  score : 0.0\n",
      "hidden layer sizes : (10, 10),\t  score : 0.8372093023255814\n"
     ]
    }
   ],
   "source": [
    "# hidden layer sizes list => hls_lst\n",
    "hls_lst = [(5, ), (10, ), (3, 3), (5, 5), (10, 10)]  # (5, ) => 층이 1개, 노드가 5개 \n",
    "\n",
    "# 넓은 범위에서 선 탐색\n",
    "for hidden_layer_sizes in hls_lst :\n",
    "    score = MLP_model_test(hidden_layer_sizes= hidden_layer_sizes)\n",
    "    print('hidden layer sizes : {},\\t  score : {}'.format(hidden_layer_sizes, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_iter warnings 발생  \n",
    "은닉층 사이즈가 (5, 5) 일 때, f1 score가 0 이 나옴  =>  초기값의 영향 ..? (더 단순한 모델과 더 복잡한 모델 둘 다 성능이 나왔으므로.)\n",
    "  \n",
    "f1 score 가 잘 나온 순서는 앞에서 부터 다음과 같다. (10, 10) > (10, ) > ...   => 은닉노드가 많을 수록 좋은 결과가 나왔다.   \n",
    "=> 더 복잡한 모델을 고려해야한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter : {'hidden_layer_sizes': (14,), 'max_iter': 200, 'random_state': 41},\n",
      "\t  score : 0.8695652173913043 \n",
      "parameter : {'hidden_layer_sizes': (14,), 'max_iter': 200, 'random_state': 102},\n",
      "\t  score : 0.8444444444444444 \n",
      "parameter : {'hidden_layer_sizes': (14,), 'max_iter': 200, 'random_state': 15},\n",
      "\t  score : 0.8260869565217391 \n",
      "parameter : {'hidden_layer_sizes': (14,), 'max_iter': 2000, 'random_state': 41},\n",
      "\t  score : 0.888888888888889 \n",
      "parameter : {'hidden_layer_sizes': (14,), 'max_iter': 2000, 'random_state': 102},\n",
      "\t  score : 0.8695652173913043 \n",
      "parameter : {'hidden_layer_sizes': (14,), 'max_iter': 2000, 'random_state': 15},\n",
      "\t  score : 0.888888888888889 \n",
      "parameter : {'hidden_layer_sizes': (14,), 'max_iter': 20000, 'random_state': 41},\n",
      "\t  score : 0.888888888888889 \n",
      "parameter : {'hidden_layer_sizes': (14,), 'max_iter': 20000, 'random_state': 102},\n",
      "\t  score : 0.8695652173913043 \n",
      "parameter : {'hidden_layer_sizes': (14,), 'max_iter': 20000, 'random_state': 15},\n",
      "\t  score : 0.888888888888889 \n",
      "parameter : {'hidden_layer_sizes': (5, 5), 'max_iter': 200, 'random_state': 41},\n",
      "\t  score : 0.7777777777777778 \n",
      "parameter : {'hidden_layer_sizes': (5, 5), 'max_iter': 200, 'random_state': 102},\n",
      "\t  score : 0.8085106382978724 \n",
      "parameter : {'hidden_layer_sizes': (5, 5), 'max_iter': 200, 'random_state': 15},\n",
      "\t  score : 0.8260869565217391 \n",
      "parameter : {'hidden_layer_sizes': (5, 5), 'max_iter': 2000, 'random_state': 41},\n",
      "\t  score : 0.8444444444444444 \n",
      "parameter : {'hidden_layer_sizes': (5, 5), 'max_iter': 2000, 'random_state': 102},\n",
      "\t  score : 0.8333333333333333 \n",
      "parameter : {'hidden_layer_sizes': (5, 5), 'max_iter': 2000, 'random_state': 15},\n",
      "\t  score : 0.8695652173913043 \n",
      "parameter : {'hidden_layer_sizes': (5, 5), 'max_iter': 20000, 'random_state': 41},\n",
      "\t  score : 0.8444444444444444 \n",
      "parameter : {'hidden_layer_sizes': (5, 5), 'max_iter': 20000, 'random_state': 102},\n",
      "\t  score : 0.8333333333333333 \n",
      "parameter : {'hidden_layer_sizes': (5, 5), 'max_iter': 20000, 'random_state': 15},\n",
      "\t  score : 0.8695652173913043 \n",
      "parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 200, 'random_state': 41},\n",
      "\t  score : 0.888888888888889 \n",
      "parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 200, 'random_state': 102},\n",
      "\t  score : 0.7441860465116279 \n",
      "parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 200, 'random_state': 15},\n",
      "\t  score : 0.8636363636363636 \n",
      "parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 2000, 'random_state': 41},\n",
      "\t  score : 0.8936170212765958 \n",
      "parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 2000, 'random_state': 102},\n",
      "\t  score : 0.875 \n",
      "parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 2000, 'random_state': 15},\n",
      "\t  score : 0.9361702127659575 \n",
      "parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 20000, 'random_state': 41},\n",
      "\t  score : 0.8936170212765958 \n",
      "parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 20000, 'random_state': 102},\n",
      "\t  score : 0.875 \n",
      "parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 20000, 'random_state': 15},\n",
      "\t  score : 0.9361702127659575 \n",
      "parameter : {'hidden_layer_sizes': (11, 13), 'max_iter': 200, 'random_state': 41},\n",
      "\t  score : 0.8571428571428572 \n",
      "parameter : {'hidden_layer_sizes': (11, 13), 'max_iter': 200, 'random_state': 102},\n",
      "\t  score : 0.8510638297872342 \n",
      "parameter : {'hidden_layer_sizes': (11, 13), 'max_iter': 200, 'random_state': 15},\n",
      "\t  score : 0.9090909090909091 \n",
      "parameter : {'hidden_layer_sizes': (11, 13), 'max_iter': 2000, 'random_state': 41},\n",
      "\t  score : 0.9130434782608695 \n",
      "parameter : {'hidden_layer_sizes': (11, 13), 'max_iter': 2000, 'random_state': 102},\n",
      "\t  score : 0.9130434782608695 \n",
      "parameter : {'hidden_layer_sizes': (11, 13), 'max_iter': 2000, 'random_state': 15},\n",
      "\t  score : 0.8510638297872342 \n",
      "parameter : {'hidden_layer_sizes': (11, 13), 'max_iter': 20000, 'random_state': 41},\n",
      "\t  score : 0.9130434782608695 \n",
      "parameter : {'hidden_layer_sizes': (11, 13), 'max_iter': 20000, 'random_state': 102},\n",
      "\t  score : 0.9130434782608695 \n",
      "parameter : {'hidden_layer_sizes': (11, 13), 'max_iter': 20000, 'random_state': 15},\n",
      "\t  score : 0.8510638297872342 \n",
      "parameter : {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 200, 'random_state': 41},\n",
      "\t  score : 0.5142857142857142 \n",
      "parameter : {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 200, 'random_state': 102},\n",
      "\t  score : 0.5945945945945945 \n",
      "parameter : {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 200, 'random_state': 15},\n",
      "\t  score : 0.7924528301886793 \n",
      "parameter : {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 2000, 'random_state': 41},\n",
      "\t  score : 0.8510638297872342 \n",
      "parameter : {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 2000, 'random_state': 102},\n",
      "\t  score : 0.7826086956521738 \n",
      "parameter : {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 2000, 'random_state': 15},\n",
      "\t  score : 0.8510638297872342 \n",
      "parameter : {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 20000, 'random_state': 41},\n",
      "\t  score : 0.8510638297872342 \n",
      "parameter : {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 20000, 'random_state': 102},\n",
      "\t  score : 0.7826086956521738 \n",
      "parameter : {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 20000, 'random_state': 15},\n",
      "\t  score : 0.8510638297872342 \n",
      "parameter : {'hidden_layer_sizes': (10, 10, 10), 'max_iter': 200, 'random_state': 41},\n",
      "\t  score : 0.888888888888889 \n",
      "parameter : {'hidden_layer_sizes': (10, 10, 10), 'max_iter': 200, 'random_state': 102},\n",
      "\t  score : 0.8636363636363636 \n",
      "parameter : {'hidden_layer_sizes': (10, 10, 10), 'max_iter': 200, 'random_state': 15},\n",
      "\t  score : 0.8636363636363636 \n",
      "parameter : {'hidden_layer_sizes': (10, 10, 10), 'max_iter': 2000, 'random_state': 41},\n",
      "\t  score : 0.9361702127659575 \n",
      "parameter : {'hidden_layer_sizes': (10, 10, 10), 'max_iter': 2000, 'random_state': 102},\n",
      "\t  score : 0.875 \n",
      "parameter : {'hidden_layer_sizes': (10, 10, 10), 'max_iter': 2000, 'random_state': 15},\n",
      "\t  score : 0.8979591836734693 \n",
      "parameter : {'hidden_layer_sizes': (10, 10, 10), 'max_iter': 20000, 'random_state': 41},\n",
      "\t  score : 0.9361702127659575 \n",
      "parameter : {'hidden_layer_sizes': (10, 10, 10), 'max_iter': 20000, 'random_state': 102},\n",
      "\t  score : 0.875 \n",
      "parameter : {'hidden_layer_sizes': (10, 10, 10), 'max_iter': 20000, 'random_state': 15},\n",
      "\t  score : 0.8979591836734693 \n",
      "------------------------------------------------------------\n",
      "best_parameter : {'hidden_layer_sizes': (10, 10), 'max_iter': 2000, 'random_state': 15},\t  best_score : 0.9361702127659575\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 그리드 설정\n",
    "MLP_parameter_grid = ParameterGrid({\"random_state\": [41, 102, 15],\n",
    "                                  \"hidden_layer_sizes\": [(14, ), (5, 5), (10, 10), (11, 13), (5, 5, 5), (10, 10, 10)],\n",
    "                                   \"max_iter\":[200, 2000, 20000]})\n",
    "\n",
    "# 파라미터 튜닝 수행 \n",
    "best_score = -1\n",
    "for parameter in MLP_parameter_grid:\n",
    "    model = MLPClassifier(**parameter).fit(Train_X, Train_Y)\n",
    "    pred_Y = model.predict(Test_X)\n",
    "    score = f1_score(Test_Y, pred_Y)\n",
    "    \n",
    "    print('parameter : {},'.format(parameter))\n",
    "    print('\\t  score : {} '.format(score))\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameter = parameter\n",
    "\n",
    "\n",
    "print('-'*60)\n",
    "print('best_parameter : {},\\t  best_score : {}'.format(best_parameter, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip\n",
    "seed 값은 결과에 큰 영향을 주지 않음.  \n",
    "\n",
    "결과적으로 **EDA와 Feature Engineering**이 중요.  \n",
    "\n",
    "?  또 다른 Tuning 팁은(대회 전용 잡기술) 3개를 제출했을 때 parameter 값들을 기준으로 범위를 잡아서 제출하는 것도 한 방법임(대회 막바지 기준)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
