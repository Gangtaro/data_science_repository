{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차 검증 반복자 (Cross Validation iterators)\n",
    "\n",
    "ref. [참고 자료](https://davinci-ai.tistory.com/18)  \n",
    "**반복자의 선정은 데이터 세트의 모양과 구조에 따라 신중하게 선택이 되어야 합니다. 일반적으로 독립적인지, 동일한 분포인지를 보게 됩니다**\n",
    "\n",
    "1. **데이터가 독립적이고 동일한 분포를 가진 경우**  \n",
    "    - KFold\n",
    "    - RepeatedKFold\n",
    "    - LeaveOneOut(LOO)\n",
    "    - LeavePOutLeaveOneOut(LPO)\n",
    "    \n",
    "    \n",
    "2. **동일한 분포가 아닌 경우**  \n",
    "    - StratifiedKFold \n",
    "    - RepeatedStratifiedKFold\n",
    "    - StratifiedShuffleSplit\n",
    "    \n",
    "    \n",
    "3. **그룹화된 데이터의 경우**  \n",
    "    - GroupKFold\n",
    "    - LeaveOneGroupOut\n",
    "    - LeavePGroupsOut\n",
    "    - GroupShuffleSplit\n",
    "    \n",
    "    \n",
    "4. **시계열 데이터의 경우**  \n",
    "    - TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import modules and data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris, load_diabetes\n",
    "iris   = load_iris()\n",
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터가 독립적이고 동일한 분포를 가진 경우\n",
    "\n",
    "### KFold\n",
    "---\n",
    "**k-fold cross validation**\n",
    "- 모든 데이터를 K개의 Fold로 나누고, 이를 split하여 총 k번의 시행에서 각각 n번째가 fold를 test set의 역할을 한다. n=1,2, ... , K \n",
    "\n",
    "<img src=\"./_images/kfold.png\" height=\"75%\" width=\"75%\">\n",
    "\n",
    "- 'shuffle = True' : 전체 데이터를 Split 하기 전에 한 번 뒤 섞는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle= False, random_state = None)\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in kf.split( iris['data'] ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RepeatedKFold\n",
    "---\n",
    "**Repeated k-fold cross validation**\n",
    "\n",
    "- **k-fold cross validation**을 **n**번 시행한 것임\n",
    "- 'shuffle = True' 가 기본 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "rkf = RepeatedKFold(n_splits = 5, n_repeats = 2, random_state = None)\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in rkf.split( iris['data'] ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeaveOneOut (LOO)\n",
    "---\n",
    "전체 데이터에서 하나의 관측치를 제외하고 Train set으로 사용하고 제외한 관측치를 test 용도로 사용한다.\n",
    "\n",
    "- <=> **하나의 관측치만**을 TEST SET으로 설정\n",
    "- 데이터의 개수가 적을 때, 데이터의 낭비를 막는 방법\n",
    "- 결과값들의 분산이 높게 나오는 경우가 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in loo.split( iris['data'] ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeavePOut (LPO)\n",
    "---\n",
    "**LPO** = LOO + K-fold\n",
    "- LOO와 마찬가지로 양이 적은 데이터에서 데이터 손실을 막기 위해 고안된 방법\n",
    "- 전체 데이터에서 **p**개 관측치들을 제외 (모든 조합의 수), 나머지를 Train set, 제외된 관측치들을 Test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "lpo = lpo = LeavePOut(p=2)\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in lpo.split( iris['data'] ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(test_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShuffleSplit\n",
    "---\n",
    "- k-fold 기반의 방법들과는 다르게 **중복**의 가능성이 있다. (완전 배타를 보장하지 않는다.)\n",
    "- **n**번의 반복 마다, **test_size** 만큼의 관측치를 test set으로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit \n",
    "\n",
    "ss = ShuffleSplit(n_splits= 5, test_size= 0.3, random_state= 9505)\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in ss.split( iris['data'] ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 동일한 분포가 아닌 경우\n",
    "\n",
    "### StratifiedKFold\n",
    "- 분류 문제에서 label의 비율은 Learning에서 아주 중요하게 적용될 수 있다.\n",
    "- **lable의 비율을 유지**하면서 Train set, Test set을 K-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 4)\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split( iris['data'], iris['target'] ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupKFold\n",
    "---\n",
    "\n",
    "- 데이터에 Lable을 제외하고 범주형으로 구분된 Group 변수가 존재한다면, 그룹단위로 split 하여 Train set, Test set으로 나눈다.\n",
    "- 이 때, Test set에 하나의 그룹만 존재한다는 것은 아님.\n",
    "- 그리고 어떤 Group이든 Train 또는 Test set 둘 중 하나에만 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf5ca84ca0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Edit data for new group \n",
    "df_iris = pd.DataFrame(iris.data)\n",
    "df_iris[3].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3  group\n",
       "0    5.1  3.5  1.4  0.2      0\n",
       "1    4.9  3.0  1.4  0.2      0\n",
       "2    4.7  3.2  1.3  0.2      0\n",
       "3    4.6  3.1  1.5  0.2      0\n",
       "4    5.0  3.6  1.4  0.2      0\n",
       "..   ...  ...  ...  ...    ...\n",
       "145  6.7  3.0  5.2  2.3      4\n",
       "146  6.3  2.5  5.0  1.9      3\n",
       "147  6.5  3.0  5.2  2.0      3\n",
       "148  6.2  3.4  5.4  2.3      4\n",
       "149  5.9  3.0  5.1  1.8      3\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group 변수 추가\n",
    "df_iris['group'] = 0\n",
    "df_iris.loc[df_iris[3] > 0.75, 'group'] = 1\n",
    "df_iris.loc[df_iris[3] > 1.25, 'group'] = 2\n",
    "df_iris.loc[df_iris[3] > 1.75, 'group'] = 3\n",
    "df_iris.loc[df_iris[3] > 2.1, 'group'] = 4\n",
    "\n",
    "# group 변수 추출\n",
    "group = df_iris['group']\n",
    "\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Group 별 index]\n",
      "\n",
      "Group-1\n",
      " : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "\n",
      "Group-2\n",
      " : [57, 60, 62, 67, 69, 73, 79, 80, 81, 82, 90, 92, 93, 95, 98]\n",
      "\n",
      "Group-3\n",
      " : [50, 51, 52, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 66, 68, 71, 72, 74, 75, 76, 77, 78, 83, 84, 85, 86, 87, 88, 89, 91, 94, 96, 97, 99, 106, 119, 129, 133, 134]\n",
      "\n",
      "Group-4\n",
      " : [70, 101, 102, 103, 105, 107, 108, 110, 111, 112, 113, 116, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 137, 138, 139, 142, 146, 147, 149]\n",
      "\n",
      "Group-5\n",
      " : [100, 104, 109, 114, 115, 117, 118, 120, 132, 135, 136, 140, 141, 143, 144, 145, 148]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group 별 인덱스\n",
    "print('[Group 별 index]\\n')\n",
    "\n",
    "list(df_iris[df_iris['group'] == 0].index)\n",
    "n = df_iris['group'].nunique()\n",
    "\n",
    "for i in range(n) : \n",
    "    print('Group-{}\\n : {}\\n'.format(i+1, list(df_iris[df_iris['group'] == i].index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1-th iteration]\n",
      "- train set size : 100, test set size : 50\n",
      "- Index of test set is \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "\n",
      "[2-th iteration]\n",
      "- train set size : 96, test set size : 54\n",
      "- Index of test set is \n",
      "[50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 106, 119, 129, 133, 134]\n",
      "\n",
      "[3-th iteration]\n",
      "- train set size : 104, test set size : 46\n",
      "- Index of test set is \n",
      "[70, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in gkf.split( iris['data'], groups= group ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeaveOneGroupOut\n",
    "---\n",
    "- 전체 데이터에서 Group들 중에 하나의 Group만 제외하고, 나머지 관측치를 Traing set으로 사용하고 제외된 관측치를 Test set으로 설정\n",
    "- **시간과 관련된 데이터에서 많이 사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1-th iteration]\n",
      "- train set size : 100, test set size : 50\n",
      "- Index of test set is \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "\n",
      "[2-th iteration]\n",
      "- train set size : 135, test set size : 15\n",
      "- Index of test set is \n",
      "[57, 60, 62, 67, 69, 73, 79, 80, 81, 82, 90, 92, 93, 95, 98]\n",
      "\n",
      "[3-th iteration]\n",
      "- train set size : 111, test set size : 39\n",
      "- Index of test set is \n",
      "[50, 51, 52, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 66, 68, 71, 72, 74, 75, 76, 77, 78, 83, 84, 85, 86, 87, 88, 89, 91, 94, 96, 97, 99, 106, 119, 129, 133, 134]\n",
      "\n",
      "[4-th iteration]\n",
      "- train set size : 121, test set size : 29\n",
      "- Index of test set is \n",
      "[70, 101, 102, 103, 105, 107, 108, 110, 111, 112, 113, 116, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 137, 138, 139, 142, 146, 147, 149]\n",
      "\n",
      "[5-th iteration]\n",
      "- train set size : 133, test set size : 17\n",
      "- Index of test set is \n",
      "[100, 104, 109, 114, 115, 117, 118, 120, 132, 135, 136, 140, 141, 143, 144, 145, 148]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in logo.split( iris['data'], groups= group ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeavePGroupsOut\n",
    "---\n",
    "- 전체 데이터에서 p개의 group을 제외하고, 나머지 데이터를 train set으로 사용하고 나머지는 test set으로 사용한다.\n",
    "- n개의 group이 있다고 할 때, n개중 p개의 모든 조합을 사용한다. (nCp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1-th iteration]\n",
      "- train set size : 85, test set size : 65\n",
      "- Index of test set is \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 57, 60, 62, 67, 69, 73, 79, 80, 81, 82, 90, 92, 93, 95, 98]\n",
      "\n",
      "[2-th iteration]\n",
      "- train set size : 61, test set size : 89\n",
      "- Index of test set is \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 66, 68, 71, 72, 74, 75, 76, 77, 78, 83, 84, 85, 86, 87, 88, 89, 91, 94, 96, 97, 99, 106, 119, 129, 133, 134]\n",
      "\n",
      "[3-th iteration]\n",
      "- train set size : 71, test set size : 79\n",
      "- Index of test set is \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 70, 101, 102, 103, 105, 107, 108, 110, 111, 112, 113, 116, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 137, 138, 139, 142, 146, 147, 149]\n",
      "\n",
      "[4-th iteration]\n",
      "- train set size : 83, test set size : 67\n",
      "- Index of test set is \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 100, 104, 109, 114, 115, 117, 118, 120, 132, 135, 136, 140, 141, 143, 144, 145, 148]\n",
      "\n",
      "[5-th iteration]\n",
      "- train set size : 96, test set size : 54\n",
      "- Index of test set is \n",
      "[50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 106, 119, 129, 133, 134]\n",
      "\n",
      "[6-th iteration]\n",
      "- train set size : 106, test set size : 44\n",
      "- Index of test set is \n",
      "[57, 60, 62, 67, 69, 70, 73, 79, 80, 81, 82, 90, 92, 93, 95, 98, 101, 102, 103, 105, 107, 108, 110, 111, 112, 113, 116, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 137, 138, 139, 142, 146, 147, 149]\n",
      "\n",
      "[7-th iteration]\n",
      "- train set size : 118, test set size : 32\n",
      "- Index of test set is \n",
      "[57, 60, 62, 67, 69, 73, 79, 80, 81, 82, 90, 92, 93, 95, 98, 100, 104, 109, 114, 115, 117, 118, 120, 132, 135, 136, 140, 141, 143, 144, 145, 148]\n",
      "\n",
      "[8-th iteration]\n",
      "- train set size : 82, test set size : 68\n",
      "- Index of test set is \n",
      "[50, 51, 52, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 77, 78, 83, 84, 85, 86, 87, 88, 89, 91, 94, 96, 97, 99, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 116, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 137, 138, 139, 142, 146, 147, 149]\n",
      "\n",
      "[9-th iteration]\n",
      "- train set size : 94, test set size : 56\n",
      "- Index of test set is \n",
      "[50, 51, 52, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 66, 68, 71, 72, 74, 75, 76, 77, 78, 83, 84, 85, 86, 87, 88, 89, 91, 94, 96, 97, 99, 100, 104, 106, 109, 114, 115, 117, 118, 119, 120, 129, 132, 133, 134, 135, 136, 140, 141, 143, 144, 145, 148]\n",
      "\n",
      "[10-th iteration]\n",
      "- train set size : 104, test set size : 46\n",
      "- Index of test set is \n",
      "[70, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "\n",
    "lpgo = LeavePGroupsOut(2)\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in lpgo.split( iris['data'], groups= group ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupShuffleSplit\n",
    "---\n",
    "- GroupShuffleSplit = ShuffleSplit + GroupKFold\n",
    "- 같은 그룹을 공유하는 관측치는 Train or Test set 무조건 둘 중 하나에 속한다.\n",
    "- 하지만, 반복마다 일정 비율만큼의 group을 test set으로 사용한다. 즉 반복자 간에 완전한 중복이 있지 않다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1-th iteration]\n",
      "- train set size : 96, test set size : 54\n",
      "- Index of test set is \n",
      "[50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 106, 119, 129, 133, 134]\n",
      "\n",
      "[2-th iteration]\n",
      "- train set size : 104, test set size : 46\n",
      "- Index of test set is \n",
      "[70, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "\n",
      "[3-th iteration]\n",
      "- train set size : 118, test set size : 32\n",
      "- Index of test set is \n",
      "[57, 60, 62, 67, 69, 73, 79, 80, 81, 82, 90, 92, 93, 95, 98, 100, 104, 109, 114, 115, 117, 118, 120, 132, 135, 136, 140, 141, 143, 144, 145, 148]\n",
      "\n",
      "[4-th iteration]\n",
      "- train set size : 96, test set size : 54\n",
      "- Index of test set is \n",
      "[50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 106, 119, 129, 133, 134]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "lpgo = GroupShuffleSplit(n_splits = 4, test_size = 0.3, random_state= 9505)\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in lpgo.split( iris['data'], groups= group ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 데이터인 경우\n",
    "\n",
    "### TimeSeriesSplit\n",
    "---\n",
    "- 시계열 데이터는 시간순을 유지해야하기 때문에, 앞에서 Train data로 사용한 데이터를 그대로 사용한다.\n",
    "- 즉, Train set의 크기를 키워나가는 방향으로 반복자가 진행된다.\n",
    "\n",
    "<img src=\"./_images/tscv.png\" height=\"75%\" width=\"75%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1-th iteration]\n",
      "- train set size : 24, test set size : 21\n",
      "- Index of test set is \n",
      "[24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
      "\n",
      "[2-th iteration]\n",
      "- train set size : 45, test set size : 21\n",
      "- Index of test set is \n",
      "[45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]\n",
      "\n",
      "[3-th iteration]\n",
      "- train set size : 66, test set size : 21\n",
      "- Index of test set is \n",
      "[66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86]\n",
      "\n",
      "[4-th iteration]\n",
      "- train set size : 87, test set size : 21\n",
      "- Index of test set is \n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
      "\n",
      "[5-th iteration]\n",
      "- train set size : 108, test set size : 21\n",
      "- Index of test set is \n",
      "[108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128]\n",
      "\n",
      "[6-th iteration]\n",
      "- train set size : 129, test set size : 21\n",
      "- Index of test set is \n",
      "[129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=6)\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in tscv.split( iris['data'] ) : \n",
    "    i += 1 \n",
    "    \n",
    "    print('[{}-th iteration]\\n- train set size : {}, test set size : {}'.format(i, len(train_idx), len(test_idx)))\n",
    "    print('- Index of test set is \\n{}\\n'.format(sorted(test_idx)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 응용해서 사용할 수 있는 함수\n",
    "- cross_val_score()\n",
    "- cross_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_val_score( )\n",
    "---\n",
    "### parameters\n",
    "- **estimator :** 학습할 모델을 의미\n",
    "- **X :** 학습 시킬 DATA SET\n",
    "- **y :** 학습 시킬 Lable\n",
    "- **scoring :** (string/None)  \n",
    "    - 각 모델의 평가 방법\n",
    "    - CV는 utility function을 사용(**큰 값이 좋은 값이라고 판단**)  \n",
    "        => 따라서 MSE와 같이 작을 수록 좋은 평가 지표를 사용할 때는 'neg_mean_squared_error'와 같은 지표를 사용한다.\n",
    "- **cv :** (int/kfold)\n",
    "    - **cross validation generator**\n",
    "    - 사용할 CV 기법을 선택하면 된다. 만약에 정수로 넣을 경우 K-fold cv의 k값으로 판단한다.\n",
    "- **scores :** (returns, array) scoring을 사용하여 평가한 점수를 각각 CV 반복자의 반복마다 기록하여 표시해준다.\n",
    "- **1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
